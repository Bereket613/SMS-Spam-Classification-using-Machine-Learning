{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T12:55:58.731810Z","iopub.execute_input":"2025-08-01T12:55:58.732942Z","iopub.status.idle":"2025-08-01T12:55:58.739449Z","shell.execute_reply.started":"2025-08-01T12:55:58.732905Z","shell.execute_reply":"2025-08-01T12:55:58.738368Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Download NLTK data\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('punkt')\n\n# Constants\nVOCAB_SIZE = 3000\nMAX_LEN = 100\nEMBEDDING_DIM = 128\n\n# NEW: List of common spam keywords\nSPAM_KEYWORDS = [\n    'free', 'win', 'won', 'winner', 'cash', 'prize', 'claim', 'congratulations',\n    'urgent', 'offer', 'only', 'click', 'debt', 'call', 'reply', 'stop',\n    'sex', 'explicit', 'account', 'credit', 'loan', 'guarantee', 'money', '100%',\n    'million', 'dollars', 'pounds', 'new', 'customer'\n]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T12:56:01.226981Z","iopub.execute_input":"2025-08-01T12:56:01.227349Z","iopub.status.idle":"2025-08-01T12:56:01.234219Z","shell.execute_reply.started":"2025-08-01T12:56:01.227300Z","shell.execute_reply":"2025-08-01T12:56:01.233059Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Text preprocessing\ndef preprocess_text(text):\n    has_spam_keyword = any(keyword in text.lower() for keyword in SPAM_KEYWORDS)\n    text = text.lower()\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    tokens = nltk.word_tokenize(text)\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer()\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    if has_spam_keyword:\n        tokens.insert(0, 'spamsignal')\n    return ' '.join(tokens)\n\n# Load and prepare data\ndef load_data():\n    !wget -q https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n    !wget -q https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n    \n    train_df = pd.read_csv('train-data.tsv', sep='\\t', header=None, names=['label', 'message'])\n    test_df = pd.read_csv('valid-data.tsv', sep='\\t', header=None, names=['label', 'message'])\n    train_df['label'] = train_df['label'].map({'ham': 0, 'spam': 1})\n    test_df['label'] = test_df['label'].map({'ham': 0, 'spam': 1})\n    return train_df, test_df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T12:56:05.282622Z","iopub.execute_input":"2025-08-01T12:56:05.282938Z","iopub.status.idle":"2025-08-01T12:56:05.296482Z","shell.execute_reply.started":"2025-08-01T12:56:05.282916Z","shell.execute_reply":"2025-08-01T12:56:05.295193Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Build the model\ndef build_model():\n    model = Sequential([\n        Embedding(VOCAB_SIZE + 1, EMBEDDING_DIM, input_length=MAX_LEN),\n        Bidirectional(LSTM(64, return_sequences=True)),\n        Bidirectional(LSTM(32)),\n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer='adam',\n        metrics=['accuracy', 'Precision', 'Recall']\n    )\n    \n    return model\n\n# Main training function\ndef train_and_save_model():\n    print(\"Starting model training...\")\n    train_df, test_df = load_data()\n    all_messages = pd.concat([train_df['message'], test_df['message']])\n    all_labels = pd.concat([train_df['label'], test_df['label']])\n    all_messages_processed = all_messages.apply(preprocess_text)\n    X_train, X_val, y_train, y_val = train_test_split(\n        all_messages_processed, all_labels, test_size=0.2, random_state=42, stratify=all_labels)\n    \n    tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<OOV>')\n    tokenizer.word_index['spamsignal'] = len(tokenizer.word_index) + 1\n    tokenizer.fit_on_texts(X_train)\n    \n    train_sequences = tokenizer.texts_to_sequences(X_train)\n    train_padded = pad_sequences(train_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n    val_sequences = tokenizer.texts_to_sequences(X_val)\n    val_padded = pad_sequences(val_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n    \n    model = build_model()\n    \n    history = model.fit(\n        train_padded,\n        y_train,\n        epochs=10,\n        validation_data=(val_padded, y_val),\n        callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n        batch_size=64,\n        verbose=1\n    )\n    \n    print(\"\\nTraining complete.\")\n    return model, tokenizer\n\n# This will run the training and return the model and tokenizer\nmodel, tokenizer = train_and_save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T12:56:07.446880Z","iopub.execute_input":"2025-08-01T12:56:07.447169Z","iopub.status.idle":"2025-08-01T12:57:55.905566Z","shell.execute_reply.started":"2025-08-01T12:56:07.447151Z","shell.execute_reply":"2025-08-01T12:57:55.904266Z"}},"outputs":[{"name":"stdout","text":"Starting model training...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 222ms/step - Precision: 0.3946 - Recall: 0.1701 - accuracy: 0.8399 - loss: 0.4007 - val_Precision: 0.9739 - val_Recall: 0.7467 - val_accuracy: 0.9632 - val_loss: 0.1204\nEpoch 2/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 225ms/step - Precision: 0.9735 - Recall: 0.8774 - accuracy: 0.9811 - loss: 0.0775 - val_Precision: 0.9643 - val_Recall: 0.9000 - val_accuracy: 0.9821 - val_loss: 0.0518\nEpoch 3/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 225ms/step - Precision: 0.9791 - Recall: 0.9506 - accuracy: 0.9906 - loss: 0.0392 - val_Precision: 0.9853 - val_Recall: 0.8933 - val_accuracy: 0.9839 - val_loss: 0.0509\nEpoch 4/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 224ms/step - Precision: 0.9884 - Recall: 0.9756 - accuracy: 0.9948 - loss: 0.0218 - val_Precision: 0.9854 - val_Recall: 0.9000 - val_accuracy: 0.9848 - val_loss: 0.0633\nEpoch 5/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 217ms/step - Precision: 0.9942 - Recall: 0.9637 - accuracy: 0.9948 - loss: 0.0229 - val_Precision: 0.9855 - val_Recall: 0.9067 - val_accuracy: 0.9857 - val_loss: 0.0714\nEpoch 6/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 202ms/step - Precision: 0.9893 - Recall: 0.9846 - accuracy: 0.9966 - loss: 0.0135 - val_Precision: 0.9714 - val_Recall: 0.9067 - val_accuracy: 0.9839 - val_loss: 0.0582\n\nTraining complete.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"\n    # Gradio interface\n    def predict_message(text):\n        try:\n            # Preprocess\n            processed_text = preprocess_text(text)\n            # Tokenize\n            sequence = tokenizer.texts_to_sequences([processed_text])\n            padded = pad_sequences(sequence, maxlen=MAX_LEN, padding='post', truncating='post')\n            # Predict\n            prediction = model.predict(padded, verbose=0)[0][0]\n            # Format results\n            label = \"SPAM\" if prediction > 0.5 else \"HAM\"\n            confidence = prediction if label == \"SPAM\" else 1 - prediction\n            color = \"#FF5733\" if label == \"SPAM\" else \"#33FF57\"\n            \n            return (label, \n                    f\"{confidence:.2%}\", \n                    f\"<div style='background-color:{color}; padding:20px; border-radius:10px; text-align:center;'>{label}</div>\")\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return (\"ERROR\", \"0%\", \"<div style='background-color:#CCCCCC; padding:20px; border-radius:10px; text-align:center;'>ERROR</div>\")\n    \n    # Create interface\n    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n        gr.Markdown(\"# üì± SMS Spam Classifier\")\n        gr.Markdown(\"Enter a message to check if it's spam or legitimate (ham)\")\n        \n        with gr.Row():\n            with gr.Column():\n                input_text = gr.Textbox(label=\"Message\", lines=3)\n                submit_btn = gr.Button(\"Classify\", variant=\"primary\")\n                gr.Examples(\n                    examples=[\n                        \"WINNER!! You won 1 million dollars! Click here to claim!\",\n                        \"Hi, how are you doing today?\",\n                        \"URGENT: Your bank account has been compromised\",\n                        \"Your package will arrive tomorrow\"\n                    ],\n                    inputs=input_text\n                )\n            \n            with gr.Column():\n                output_label = gr.Label(label=\"Result\")\n                confidence = gr.Textbox(label=\"Confidence\")\n                output_display = gr.HTML()\n        \n        submit_btn.click(\n            fn=predict_message,\n            inputs=input_text,\n            outputs=[output_label, confidence, output_display]\n        )\n    \n    demo.launch()\n    if __name__ == \"__main__\":\n        main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T12:57:59.734759Z","iopub.execute_input":"2025-08-01T12:57:59.735097Z","iopub.status.idle":"2025-08-01T12:59:46.658514Z","shell.execute_reply.started":"2025-08-01T12:57:59.735058Z","shell.execute_reply":"2025-08-01T12:59:46.657397Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7862\nIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://d2ad261e7d0760130a.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://d2ad261e7d0760130a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 249ms/step - Precision: 0.4902 - Recall: 0.1728 - accuracy: 0.8620 - loss: 0.3677 - val_Precision: 0.8874 - val_Recall: 0.8933 - val_accuracy: 0.9704 - val_loss: 0.0950\nEpoch 2/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 205ms/step - Precision: 0.9626 - Recall: 0.8942 - accuracy: 0.9814 - loss: 0.0752 - val_Precision: 0.9716 - val_Recall: 0.9133 - val_accuracy: 0.9848 - val_loss: 0.0514\nEpoch 3/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 211ms/step - Precision: 0.9701 - Recall: 0.9502 - accuracy: 0.9891 - loss: 0.0413 - val_Precision: 0.9658 - val_Recall: 0.9400 - val_accuracy: 0.9874 - val_loss: 0.0458\nEpoch 4/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 197ms/step - Precision: 0.9992 - Recall: 0.9746 - accuracy: 0.9965 - loss: 0.0116 - val_Precision: 0.9714 - val_Recall: 0.9067 - val_accuracy: 0.9839 - val_loss: 0.0633\nEpoch 5/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 194ms/step - Precision: 0.9939 - Recall: 0.9874 - accuracy: 0.9975 - loss: 0.0104 - val_Precision: 0.9396 - val_Recall: 0.9333 - val_accuracy: 0.9830 - val_loss: 0.0717\nEpoch 6/10\n\u001b[1m70/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 200ms/step - Precision: 0.9893 - Recall: 0.9907 - accuracy: 0.9973 - loss: 0.0089 - val_Precision: 0.9586 - val_Recall: 0.9267 - val_accuracy: 0.9848 - val_loss: 0.0663\n","output_type":"stream"}],"execution_count":17}]}